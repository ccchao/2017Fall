{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT/CS 287 MIDTERM\n",
    "### Chia-Chun Chao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. how well Jarvis works:\n",
    "\n",
    "#### i) what needs to be improved to make it better at recognizing natural language\n",
    "\n",
    "The length of each document influences the result of classification. Because the training data I sent is mostly short daily sentences, there are not enough words for precise classification. To improve Jarvis, we need to create more training data and also type more words in each document to make it longer.\n",
    "\n",
    "If we can provide priority of important words in a sentence, the accuracy will be much better. For example, \"Is it time for pizza?\" and \"Do you want a pizza at this time?\" contain a \"time\" and a \"pizza\" in a document, and both are classified as TIME using the Multinomial Naïve Bayes classifier. Apparently, the latter one should be classified as PIZZA. To do this, the classifier should be able to determine the priority based on the positions of time and pizza instead of only counting the number of each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) what you estimate Jarvis’ classification accuracy to be (including an argument for how you can measure this). This requires a statistical analysis.\n",
    "\n",
    "For the analysis, I create 5 testing data for each class.  \n",
    "\n",
    "- TIME: ['What day is it today?','When will you start testing?','Am I late now?','How long have you been testing?','What is the date today?']\n",
    "- PIZZA: ['Grab me a pizza','Give me food','I want to order a whole chicken pizza with extra cheese','What kind of pizza do you have?','Bring me food with a lot of cheese']\n",
    "- GREET: ['How are you today?','Have a good day?','How’s everything going?','Glad to meet you','It's great seeing you.']\n",
    "- WEATHER: ['Is today a snow day?','Is it raining? Sunny? Or snowing?','What is the average temperature today?','Is today cold enough to wear a scarf?','Is it possible to rain this afternoon?']\n",
    "- JOKE: ['Tell me something interesting','Make me laugh with some jokes','Is there any joke for me today?','A joke will break the silence now','Funny jokes are needed right now']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When multinomial Naïve Bayes classifier is used, the correctness is 0.64. And the wrongly classified documents include:\n",
    "\n",
    "1. What day is it today? (TIME) => WEATHER\n",
    "- Am I late now? (TIME) => WEATHER\n",
    "- How long have you been testing? (TIME) => GREET\n",
    "- What is the date today? (TIME) => WEATHER\n",
    "- Give me food (PIZZA) => TIME\n",
    "- What kind of pizza do you have? (PIZZA) => TIME\n",
    "- It's great seeing you. (GREET) => TIME\n",
    "- A joke will break the silence now (JOKE) => WEATHER\n",
    "- Funny jokes are needed (JOKE) => GREET\n",
    "\n",
    "When support vector machine (SVM) is used, the correctness is 0.76. And the wrongly classified documents include:\n",
    "\n",
    "1. What day is it today? (TIME) => WEATHER\n",
    "- How long have you been testing? (TIME) => GREET\n",
    "- What is the date today? (TIME) => WEATHER\n",
    "- Give me food (PIZZA) => TIME\n",
    "- It's great seeing you. (GREET) => TIME\n",
    "- Tell me something interesting (JOKE) => TIME\n",
    "\n",
    "SVM corrects 2, 6, 8, and 9 of wrongly classified documents by Naïve Bayes, but make 'Tell me something interesting' wrongly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also estimate Jarvis’ classification accuracy by checking the accuracy of the training data. \n",
    "\n",
    "Using multinomial Naïve Bayes classifier, accuracy is 0.978260869565. It is not 1.0 because \"        \n",
    "what jokes do you have\" is classified as TIME instead of JOKE.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            precision    recall  f1-score   support\n",
    "\n",
    "       TIME       0.90      1.00      0.95         9\n",
    "      PIZZA       1.00      1.00      1.00        10\n",
    "      GREET       1.00      1.00      1.00        10\n",
    "    WEATHER       1.00      1.00      1.00         9\n",
    "       JOKE       1.00      0.88      0.93         8\n",
    "        avg       0.98      0.98      0.98        46\n",
    "\n",
    "\n",
    "Using support vector machine (SVM), accuracy is 1.0.\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "       TIME       1.00      1.00      1.00         9\n",
    "      PIZZA       1.00      1.00      1.00        10\n",
    "      GREET       1.00      1.00      1.00        10\n",
    "    WEATHER       1.00      1.00      1.00         9\n",
    "       JOKE       1.00      1.00      1.00         8\n",
    "        avg       1.00      1.00      1.00        46\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. a “post-mortem” describing what you (self-)learned on the project, what you struggled with, etc.\n",
    "\n",
    "In the beginning, I was surprised that we can develop a chatbot in Slack only with websocket-client package and the authentication token. Then, when designing `on_message()` function, I spent some time on different situations. For example, when Jarvis is in training mode and asked to turn into testing mode, should Jarvis finish or continue training mode? Or should he consider the request as a training document? Both finishing training mode and storing \"testing mode\" to database are less possible to be a user's intention, so I decided to not process the message but print a message showing that users need to type \"done\" and \"testing time\" to turn Jarvis to testing mode.\n",
    "\n",
    "When studying scikit-learn tutorial, I followed the instruction and implement all codes on Jarvis. I spent a lot of time on bags of words, because I could not understand why we want to create X[i,j] and what i, j, and X[i,j] refer to. Then, I used a few examples of documents and calculate X[i,j] for all words in them, and I realized that X is just a summary of the number of occurrences for each document, which is similar to a list of dictionaries but represented in a two-dimentional array.\n",
    "\n",
    "\"tf–idf\" is also a term hard to understand for me. The result value shows the degree of importance of the input word. After applying `fit()` and `transform()` functions, the weight of each word that has occured in documents is given. Fortunately, we don't need to calculate these numbers by ourselves but only implement the functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
